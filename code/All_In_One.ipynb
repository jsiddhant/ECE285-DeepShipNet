{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Basic Libs\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image Process\n",
    "from skimage.data import imread\n",
    "from skimage.morphology import label\n",
    "\n",
    "# Model Framework\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Helper Function\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../../ShipDetect/'\n",
    "train_img_dir = '../../ShipDetect/train/'\n",
    "test_img_dir = '../../ShipDetect/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(input_dir+'train_ship_segmentations_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231723, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Non-ship pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNaN(x):\n",
    "    return 0 if x==x else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['isnan'] = train_df['EncodedPixels'].apply(checkNaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    150000\n",
       "0     81723\n",
       "Name: isnan, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['isnan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 100000 Non-ship samples\n",
    "train_df = train_df.sort_values('isnan', ascending=False)\n",
    "train_df = train_df.iloc[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    81723\n",
       "1    50000\n",
       "Name: isnan, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['isnan'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate total area for labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_area_for_rle(rle_str):\n",
    "    rle_list = [int(x) if x.isdigit() else x for x in str(rle_str).split()]\n",
    "    if len(rle_list) == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        area = np.sum(rle_list[1::2])\n",
    "        return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['area'] = train_df['EncodedPixels'].apply(calc_area_for_rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_isship = train_df[train_df['area'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00123588218739\n"
     ]
    }
   ],
   "source": [
    "# Filter data by area less than 10\n",
    "train_df_smallarea = train_df_isship['area'][train_df_isship['area'] < 10]\n",
    "print(train_df_smallarea.shape[0]*1.0/train_df_isship.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>isnan</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002756f7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  isnan  area\n",
       "0  000155de5.jpg      0  3388\n",
       "1  000194a2d.jpg      0  1460\n",
       "2  0001b1832.jpg      1     0\n",
       "3  00021ddc3.jpg      0  1176\n",
       "4  0002756f7.jpg      0   408"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by imageid\n",
    "train_gp = train_df.groupby('ImageId').sum()\n",
    "train_gp = train_gp.reset_index()\n",
    "train_gp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_class(area):\n",
    "    area = area * 1.0/ (768*768)\n",
    "    if area == 0:\n",
    "        return 0\n",
    "    elif area < 0.005:\n",
    "        return 1\n",
    "    elif area < 0.015:\n",
    "        return 2\n",
    "    elif area < 0.025:\n",
    "        return 3\n",
    "    elif area < 0.035:\n",
    "        return 4\n",
    "    elif area < 0.045:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50000\n",
       "1    29315\n",
       "2     9225\n",
       "3     2644\n",
       "4     1122\n",
       "5      181\n",
       "6       69\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gp['class'] = train_gp['area'].apply(calc_class)\n",
    "train_gp['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train-Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_gp, test_size=0.01, stratify=train_gp['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_isship_list = train['ImageId'][train['isnan']==0].tolist()\n",
    "train_isship_list = random.sample(train_isship_list, len(train_isship_list))\n",
    "train_nanship_list = train['ImageId'][train['isnan']==1].tolist()\n",
    "train_nanship_list = random.sample(train_nanship_list, len(train_nanship_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42130, 49500)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_isship_list),len(train_nanship_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_mask(rle_list, SHAPE):\n",
    "    '''\n",
    "    Translate labeled pixels to the mask in the image\n",
    "    '''\n",
    "    tmp_flat = np.zeros(SHAPE[0]*SHAPE[1])\n",
    "    if len(rle_list) == 1:\n",
    "        mask = np.reshape(tmp_flat, SHAPE).T\n",
    "    else:\n",
    "        strt = rle_list[::2]\n",
    "        length = rle_list[1::2]\n",
    "        for i,v in zip(strt,length):\n",
    "            tmp_flat[(int(i)-1):(int(i)-1)+int(v)] = 255\n",
    "        mask = np.reshape(tmp_flat, SHAPE).T\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPipeline(isship, nanship, batchsize, cap):\n",
    "    k = 0\n",
    "    nanship_names, isship_names = nanship[:cap], isship[:cap]\n",
    "    while True:\n",
    "        if k+batchsize//2 >= cap:\n",
    "            k = 0\n",
    "        batch_nanship_names = nanship_names[k:k+batchsize//2]\n",
    "        batch_isship_names = isship_names[k:k+batchsize//2]\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for name in batch_nanship_names:\n",
    "            tmp_img = imread(train_img_dir + name)\n",
    "            batch_img.append(tmp_img)\n",
    "            mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n",
    "            one_mask = np.zeros((768, 768, 1))\n",
    "            for item in mask_list:\n",
    "                rle_list = str(item).split()\n",
    "                tmp_mask = rle_to_mask(rle_list, (768, 768))\n",
    "                one_mask[:,:,0] += tmp_mask\n",
    "            batch_mask.append(one_mask)\n",
    "            \n",
    "        for name in batch_isship_names:\n",
    "            tmp_img = imread(train_img_dir + name)\n",
    "            batch_img.append(tmp_img)\n",
    "            mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n",
    "            one_mask = np.zeros((768, 768, 1))\n",
    "            for item in mask_list:\n",
    "                rle_list = str(item).split()\n",
    "                tmp_mask = rle_to_mask(rle_list, (768, 768))\n",
    "                one_mask[:,:,0] += tmp_mask\n",
    "            batch_mask.append(one_mask)\n",
    "            \n",
    "        img = np.stack(batch_img, axis=0)\n",
    "        mask = np.stack(batch_mask, axis=0)\n",
    "        img = img / 255.0\n",
    "        mask = mask / 255.0\n",
    "        k += batchsize//2\n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 2\n",
    "CAP = min(len(train_isship_list),len(train_nanship_list))\n",
    "datagen = DataPipeline(train_isship_list, train_nanship_list, BATCHSIZE, CAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(768,768,3))\n",
    "conv0 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "conv0 = BatchNormalization()(conv0)\n",
    "conv0 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv0)\n",
    "conv0 = BatchNormalization()(conv0)\n",
    "\n",
    "comp0 = AveragePooling2D((6,6))(conv0)\n",
    "conv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(comp0)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Dropout(0.4)(conv1)\n",
    "\n",
    "pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "conv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Dropout(0.4)(conv2)\n",
    "\n",
    "pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Dropout(0.4)(conv3)\n",
    "\n",
    "pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "conv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Dropout(0.4)(conv4)\n",
    "\n",
    "pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "upcv6 = UpSampling2D(size=(2,2))(conv5)\n",
    "upcv6 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv6)\n",
    "upcv6 = BatchNormalization()(upcv6)\n",
    "mrge6 = concatenate([conv4, upcv6], axis=3)\n",
    "conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "upcv7 = UpSampling2D(size=(2,2))(conv6)\n",
    "upcv7 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv7)\n",
    "upcv7 = BatchNormalization()(upcv7)\n",
    "mrge7 = concatenate([conv3, upcv7], axis=3)\n",
    "conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "upcv8 = UpSampling2D(size=(2,2))(conv7)\n",
    "upcv8 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv8)\n",
    "upcv8 = BatchNormalization()(upcv8)\n",
    "mrge8 = concatenate([conv2, upcv8], axis=3)\n",
    "conv8 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge8)\n",
    "conv8 = BatchNormalization()(conv8)\n",
    "conv8 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "upcv9 = UpSampling2D(size=(2,2))(conv8)\n",
    "upcv9 = Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv9)\n",
    "upcv9 = BatchNormalization()(upcv9)\n",
    "mrge9 = concatenate([conv1, upcv9], axis=3)\n",
    "conv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge9)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "dcmp10 = UpSampling2D((6,6),interpolation='bilinear')(conv9)\n",
    "mrge10 = concatenate([dcmp10, conv0], axis=3)\n",
    "conv10 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge10)\n",
    "conv10 = BatchNormalization()(conv10)\n",
    "conv10 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv10)\n",
    "conv10 = BatchNormalization()(conv10)\n",
    "conv11 = Conv2D(1, 1, activation='sigmoid')(conv10)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=conv11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 768, 768, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 768, 768, 8)  224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 768, 768, 8)  32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 768, 768, 8)  584         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 768, 768, 8)  32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 128, 128, 8)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 16) 1168        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 16) 2320        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 32)   128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   36928       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)   0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 128)    0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 128)  131200      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 256)  0           dropout_4[0][0]                  \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 64)   32832       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           dropout_3[0][0]                  \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 32)   8224        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 32)   128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 64)   0           dropout_2[0][0]                  \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 32)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 32)   9248        batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 32)   128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 32) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 16) 2064        up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 16) 64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 32) 0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 16) 4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 16) 64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 16) 2320        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 16) 64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 768, 768, 16) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 768, 768, 24) 0           up_sampling2d_5[0][0]            \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 768, 768, 16) 3472        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 768, 768, 16) 64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 768, 768, 8)  1160        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 768, 768, 8)  32          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 768, 768, 1)  9           batch_normalization_26[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,954,265\n",
      "Trainable params: 1,950,761\n",
      "Non-trainable params: 3,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../models/checkpoint.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='../log', histogram_freq=0, write_graph=True, write_images=True)\n",
    "saveCallBack = keras.callbacks.ModelCheckpoint('../models/checkpoint.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "CallBackList = [tbCallBack, saveCallBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.0050\n",
      "Epoch 2/5\n",
      " 778/1000 [======================>.......] - ETA: 24s - loss: 0.0045"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen, steps_per_epoch = 1000, epochs = 5, callbacks=CallBackList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IoU(A, B):\n",
    "    AorB = np.logical_or(A,B).astype('int')\n",
    "    AandB = np.logical_and(A,B).astype('int')\n",
    "    IoU = AandB.sum() * 1.0 / AorB.sum()\n",
    "    return IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IoU_vector(A, B):\n",
    "    score_vector = []\n",
    "    IoU = calc_IoU(A, B)\n",
    "    for threshold in np.arange(0.5,1,0.05):\n",
    "        score = int(IoU > threshold)\n",
    "        score_vector.append(score)\n",
    "    return score_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IoU_tensor(masks_true, masks_pred):\n",
    "    true_mask_num = masks_true.shape[0]\n",
    "    pred_mask_num = masks_pred.shape[0]\n",
    "    score_tensor = np.zeros((true_mask_num, pred_mask_num, 10))\n",
    "    for true_i in range(true_mask_num):\n",
    "        for pred_i in range(pred_mask_num):\n",
    "            true_mask = masks_true[true_i]\n",
    "            pred_mask = masks_pred[pred_i]\n",
    "            score_vector = calc_IoU_vector(true_mask, pred_mask)\n",
    "            score_tensor[true_i,pred_i,:] = score_vector\n",
    "    return score_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_F2_per_one_threshold(score_matrix):\n",
    "    tp = np.sum( score_matrix.sum(axis=1) > 0  )\n",
    "    fn = np.sum( score_matrix.sum(axis=1) == 0 )\n",
    "    fp = np.sum( score_matrix.sum(axis=0) == 0 )\n",
    "    F2 = (5*tp) * 1.0 / ((5*tp) + fp + (4*fn))\n",
    "    return F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score_one_image(mask_true, mask_pred):\n",
    "    mask_true = mask_true.reshape(768,768)\n",
    "    mask_pred = mask_pred.reshape(768,768)\n",
    "    if mask_true.sum() == 0 and mask_pred.sum() == 0:\n",
    "        score = 1\n",
    "    elif mask_true.sum() == 0 and mask_pred.sum() != 0:\n",
    "        score = 0\n",
    "    elif mask_true.sum() != 0 and mask_pred.sum() == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        mask_label_true = label(mask_true)\n",
    "        mask_label_pred = label(mask_pred)\n",
    "        c_true = np.max(mask_label_true)\n",
    "        c_pred = np.max(mask_label_pred)\n",
    "        tmp = []\n",
    "        for k in range(c_true):\n",
    "            tmp.append(mask_label_true == k+1)\n",
    "        masks_true = np.stack(tmp, axis=0)\n",
    "        tmp = []\n",
    "        for k in range(c_pred):\n",
    "            tmp.append(mask_label_pred == k+1)\n",
    "        masks_pred = np.stack(tmp, axis=0)\n",
    "        score_tensor = calc_IoU_tensor(masks_true, masks_pred)\n",
    "        F2_t = []\n",
    "        for i in range(10):\n",
    "            F2 = calc_F2_per_one_threshold(score_tensor[:,:,i])\n",
    "            F2_t.append(F2)\n",
    "        score = np.mean(F2_t)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score_all_image(batch_mask_true, batch_mask_pred, threshold=0.5):\n",
    "    num = batch_mask_true.shape[0]\n",
    "    tmp = batch_mask_pred > threshold\n",
    "    batch_mask_pred = tmp.astype('int')\n",
    "    scores = list()\n",
    "    for i in range(num):\n",
    "        score = calc_score_one_image(batch_mask_true[i], batch_mask_pred[i])\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess validation set\n",
    "val_list = val['ImageId'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(image_list):\n",
    "    batch_img = []\n",
    "    batch_mask = []\n",
    "    for name in image_list:\n",
    "        tmp_img = imread(train_img_dir + name)\n",
    "        batch_img.append(tmp_img)\n",
    "        mask_list = train_df['EncodedPixels'][train_df['ImageId'] == name].tolist()\n",
    "        one_mask = np.zeros((768, 768, 1))\n",
    "        for item in mask_list:\n",
    "            rle_list = str(item).split()\n",
    "            tmp_mask = rle_to_mask(rle_list, (768, 768))\n",
    "            one_mask[:,:,0] += tmp_mask\n",
    "        batch_mask.append(one_mask)\n",
    "    img = np.stack(batch_img, axis=0)\n",
    "    mask = np.stack(batch_mask, axis=0)\n",
    "    img = img / 255.0\n",
    "    mask = mask / 255.0\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search threshold\n",
    "scores_list = dict()\n",
    "threshold_list = [x*1.0/100 for x in range(20,80,10)]\n",
    "for threshold in threshold_list:\n",
    "    scores = []\n",
    "    for i in tqdm(range(len(val_list)//2)):\n",
    "        temp_list = val_list[i*2:(i+1)*2]\n",
    "        val_img, val_mask = create_data(temp_list)\n",
    "        pred_mask = model.predict(val_img)\n",
    "        F2 = calc_score_all_image(val_mask, pred_mask, threshold=threshold)*2\n",
    "        scores.append(F2)\n",
    "    val_F2 = np.sum(scores)* (1.0/(len(val_list)//2) *2)\n",
    "    scores_list[threshold] = val_F2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_threshold = max(scores_list, key=scores_list.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = val_list[20:30]\n",
    "fig, axes = plt.subplots(len(image_list), 3, figsize=(5,5*len(image_list)))\n",
    "fig.subplots_adjust(left=0.075,right=0.95,bottom=0.05,top=0.52,wspace=0.2,hspace=0.10)\n",
    "for i in range(len(image_list)):\n",
    "    img = imread(train_img_dir + image_list[i])\n",
    "    input_img, gt_mask = create_data([image_list[i]])\n",
    "    pred_mask = model.predict(input_img)\n",
    "    pred_mask = pred_mask > opt_threshold\n",
    "    pred_mask = pred_mask.reshape(768,768,1)\n",
    "    gt_mask = gt_mask * 255\n",
    "    gt_mask = gt_mask.reshape(768,768)\n",
    "    pred_mask = pred_mask.reshape(768,768)\n",
    "    axes[i, 0].imshow(img)\n",
    "    axes[i, 1].imshow(gt_mask)\n",
    "    axes[i, 2].imshow(pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = [x.split('.')[0] for x in os.listdir(test_img_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rle_encode(img, **kwargs):\n",
    "    '''\n",
    "    Encode connected regions as separated masks\n",
    "    '''\n",
    "    labels = label(img[0,:,:,:])\n",
    "    if img.ndim > 2:\n",
    "        return [rle_encode(np.sum(labels==k, axis=2), **kwargs) for k in np.unique(labels[labels>0])]\n",
    "    else:\n",
    "        return [rle_encode(labels==k, **kwargs) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img, min_max_threshold=1e-3, max_mean_threshold=None):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    if np.max(img) < min_max_threshold:\n",
    "        return '' ## no need to encode if it's all zeros\n",
    "    if max_mean_threshold and np.mean(img) > max_mean_threshold:\n",
    "        return '' ## ignore overfilled mask\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15606/15606 [2:33:50<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_rows = []\n",
    "for name in tqdm(test_names):\n",
    "    test_img = imread(test_img_dir + name + '.jpg')\n",
    "    test_img_1 = test_img.reshape(1,768,768,3)/255.0\n",
    "    test_img_2 = test_img_1[:, :, ::-1, :]\n",
    "    test_img_3 = test_img_1[:, ::-1, :, :]\n",
    "    test_img_4 = test_img_1[:, ::-1, ::-1, :]\n",
    "    pred_prob_1 = model.predict(test_img_1)\n",
    "    pred_prob_2 = model.predict(test_img_2)\n",
    "    pred_prob_3 = model.predict(test_img_3)\n",
    "    pred_prob_4 = model.predict(test_img_4)\n",
    "    pred_prob = (pred_prob_1 + pred_prob_2[:, :, ::-1, :] + pred_prob_3[:, ::-1, :, :] + pred_prob_4[:, ::-1, ::-1, :])*1.0/4\n",
    "    pred_mask = pred_prob > opt_threshold\n",
    "    rles = multi_rle_encode(pred_mask)\n",
    "    if len(rles)>0:\n",
    "        for rle in rles:\n",
    "            pred_rows += [{'ImageId': name + '.jpg', 'EncodedPixels': rle}]\n",
    "    else:\n",
    "        pred_rows += [{'ImageId': name + '.jpg', 'EncodedPixels': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(pred_rows)[['ImageId', 'EncodedPixels']]\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
