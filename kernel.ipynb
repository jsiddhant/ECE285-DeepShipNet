{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa8401d73c7a19e1a43fdd6a992ea9dcb60039a2"
   },
   "source": [
    "# Overview\n",
    "Rather than trying to segment, we start off by making a model that simply tries to identify if any boat shows up in the image. \n",
    "For this model we can see roughly how it performs in the compititon by guessing the whole image (as an RLE) if any boat shows up (not a very smart startegy, but might provide some interesting results). \n",
    "\n",
    "## Beyond\n",
    "The model could also be useful as a quick way (low resolution images) to screen through lots of images to see if they are likely to have a boat and if they are then run a much more expensive full-resolution U-Net on that sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6cd9d5ad61ffe3b8858769f20a5f9493f024a56"
   },
   "source": [
    "## Model Parameters\n",
    "We might want to adjust these later (or do some hyperparameter optimizations). It is slightly easier to keep track of parallel notebooks with different parameters if they are all at the beginning in a clear (machine readable format, see Kaggling with Kaggle (https://www.kaggle.com/kmader/kaggling-with-kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "301a5d939c566d1487a049bb2554d09b592b18b1"
   },
   "outputs": [],
   "source": [
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 1000\n",
    "# maximum number of training images\n",
    "MAX_TRAIN_IMAGES = 15000 \n",
    "BASE_MODEL='DenseNet169' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\n",
    "IMG_SIZE = (299, 299) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 64 # [1, 8, 16, 24]\n",
    "DROPOUT = 0.5\n",
    "DENSE_COUNT = 128\n",
    "LEARN_RATE = 1e-4\n",
    "RGB_FLIP = 1 # should rgb be flipped when rendering images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ship_dir = '/datasets/ee285f-public/airbus_ship_detection/'\n",
    "train_image_dir = os.path.join(ship_dir, 'train_v2')\n",
    "test_image_dir = os.path.join(ship_dir, 'test_v2')\n",
    "import gc; gc.enable() # memory is tight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3ca7119188fbb4c6540d9df55f5833b55435287e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231723, 'masks found')\n",
      "192556\n",
      "         ImageId                                      EncodedPixels  \\\n",
      "0  00003e153.jpg                                                NaN   \n",
      "1  0001124c7.jpg                                                NaN   \n",
      "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...   \n",
      "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...   \n",
      "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...   \n",
      "\n",
      "                                                path  \n",
      "0  /datasets/ee285f-public/airbus_ship_detection/...  \n",
      "1  /datasets/ee285f-public/airbus_ship_detection/...  \n",
      "2  /datasets/ee285f-public/airbus_ship_detection/...  \n",
      "3  /datasets/ee285f-public/airbus_ship_detection/...  \n",
      "4  /datasets/ee285f-public/airbus_ship_detection/...  \n"
     ]
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join('/datasets/ee285f-public/airbus_ship_detection/',\n",
    "                                 'train_ship_segmentations_v2.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks['path'] = masks['ImageId'].map(lambda x: os.path.join(train_image_dir, x))\n",
    "print(masks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40cb72e241c0c3d8bc245b4e3c663b4a835b0011"
   },
   "source": [
    "# Split into training and validation groups\n",
    "We stratify by the number of boats appearing so we have nice balances in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "871720221ac25f7f9408bfe01aeb4ccb95edbd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 'training masks')\n",
      "(30, 'validation masks')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "train_df=train_df.truncate(after=69)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "valid_df=valid_df.truncate(after=29)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c21d5bff04bf9180463969ac120379345745ed03"
   },
   "source": [
    "### Examine Number of Ship Images\n",
    "Here we examine how often ships appear and replace the ones without any ships with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "fa2154d3621497e7497731e5ef6c6c72f27ad483"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.sample(min(MAX_TRAIN_IMAGES, train_df.shape[0])) # limit size of training set (otherwise it takes too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2612fa47c7e9fdcaa7aa720c4e15fc86fd65d69a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f9f589a3d90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f9f499721d0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[['ships', 'has_ship']].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8f65e7942816fb75b687a549dc1d5cc48d00e21"
   },
   "source": [
    "# Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"A script for testing that TensorFlow is installed correctly on Windows.\n",
    "\n",
    "The script will attempt to verify your TensorFlow installation, and print\n",
    "suggestions for how to fix your installation.\n",
    "\"\"\"\n",
    "\n",
    "import ctypes\n",
    "import imp\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "  try:\n",
    "    import tensorflow as tf\n",
    "    print(\"TensorFlow successfully installed.\")\n",
    "    if tf.test.is_built_with_cuda():\n",
    "      print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "    else:\n",
    "      print(\"The installed version of TensorFlow does not include GPU support.\")\n",
    "    sys.exit(0)\n",
    "  except ImportError:\n",
    "    print(\"ERROR: Failed to import the TensorFlow module.\")\n",
    "\n",
    "  print(\"\"\"\n",
    "WARNING! This script is no longer maintained! \n",
    "=============================================\n",
    "\n",
    "Since TensorFlow 1.4, the self-check has been integrated with TensorFlow itself,\n",
    "and any missing DLLs will be reported when you execute the `import tensorflow`\n",
    "statement. The error messages printed below refer to TensorFlow 1.3 and earlier,\n",
    "and are inaccurate for later versions of TensorFlow.\"\"\")\n",
    "    \n",
    "  candidate_explanation = False\n",
    "\n",
    "  python_version = sys.version_info.major, sys.version_info.minor\n",
    "  print(\"\\n- Python version is %d.%d.\" % python_version)\n",
    "  if not (python_version == (3, 5) or python_version == (3, 6)):\n",
    "    candidate_explanation = True\n",
    "    print(\"- The official distribution of TensorFlow for Windows requires \"\n",
    "          \"Python version 3.5 or 3.6.\")\n",
    "  \n",
    "  try:\n",
    "    _, pathname, _ = imp.find_module(\"tensorflow\")\n",
    "    print(\"\\n- TensorFlow is installed at: %s\" % pathname)\n",
    "  except ImportError:\n",
    "    candidate_explanation = False\n",
    "    print(\"\"\"\n",
    "- No module named TensorFlow is installed in this Python environment. You may\n",
    "  install it using the command `pip install tensorflow`.\"\"\")\n",
    "\n",
    "  try:\n",
    "    msvcp140 = ctypes.WinDLL(\"msvcp140.dll\")\n",
    "  except OSError:\n",
    "    candidate_explanation = True\n",
    "    print(\"\"\"\n",
    "- Could not load 'msvcp140.dll'. TensorFlow requires that this DLL be\n",
    "  installed in a directory that is named in your %PATH% environment\n",
    "  variable. You may install this DLL by downloading Microsoft Visual\n",
    "  C++ 2015 Redistributable Update 3 from this URL:\n",
    "  https://www.microsoft.com/en-us/download/details.aspx?id=53587\"\"\")\n",
    "\n",
    "  try:\n",
    "    cudart64_80 = ctypes.WinDLL(\"cudart64_80.dll\")\n",
    "  except OSError:\n",
    "    candidate_explanation = True\n",
    "    print(\"\"\"\n",
    "- Could not load 'cudart64_80.dll'. The GPU version of TensorFlow\n",
    "  requires that this DLL be installed in a directory that is named in\n",
    "  your %PATH% environment variable. Download and install CUDA 8.0 from\n",
    "  this URL: https://developer.nvidia.com/cuda-toolkit\"\"\")\n",
    "\n",
    "  try:\n",
    "    nvcuda = ctypes.WinDLL(\"nvcuda.dll\")\n",
    "  except OSError:\n",
    "    candidate_explanation = True\n",
    "    print(\"\"\"\n",
    "- Could not load 'nvcuda.dll'. The GPU version of TensorFlow requires that\n",
    "  this DLL be installed in a directory that is named in your %PATH%\n",
    "  environment variable. Typically it is installed in 'C:\\Windows\\System32'.\n",
    "  If it is not present, ensure that you have a CUDA-capable GPU with the\n",
    "  correct driver installed.\"\"\")\n",
    "\n",
    "  cudnn5_found = False\n",
    "  try:\n",
    "    cudnn5 = ctypes.WinDLL(\"cudnn64_5.dll\")\n",
    "    cudnn5_found = True\n",
    "  except OSError:\n",
    "    candidate_explanation = True\n",
    "    print(\"\"\"\n",
    "- Could not load 'cudnn64_5.dll'. The GPU version of TensorFlow\n",
    "  requires that this DLL be installed in a directory that is named in\n",
    "  your %PATH% environment variable. Note that installing cuDNN is a\n",
    "  separate step from installing CUDA, and it is often found in a\n",
    "  different directory from the CUDA DLLs. You may install the\n",
    "  necessary DLL by downloading cuDNN 5.1 from this URL:\n",
    "  https://developer.nvidia.com/cudnn\"\"\")\n",
    "\n",
    "  cudnn6_found = False\n",
    "  try:\n",
    "    cudnn = ctypes.WinDLL(\"cudnn64_6.dll\")\n",
    "    cudnn6_found = True\n",
    "  except OSError:\n",
    "    candidate_explanation = True\n",
    "\n",
    "  if not cudnn5_found or not cudnn6_found:\n",
    "    print()\n",
    "    if not cudnn5_found and not cudnn6_found:\n",
    "      print(\"- Could not find cuDNN.\")\n",
    "    elif not cudnn5_found:\n",
    "      print(\"- Could not find cuDNN 5.1.\")\n",
    "    else:\n",
    "      print(\"- Could not find cuDNN 6.\")\n",
    "      print(\"\"\"\n",
    "  The GPU version of TensorFlow requires that the correct cuDNN DLL be installed\n",
    "  in a directory that is named in your %PATH% environment variable. Note that\n",
    "  installing cuDNN is a separate step from installing CUDA, and it is often\n",
    "  found in a different directory from the CUDA DLLs. The correct version of\n",
    "  cuDNN depends on your version of TensorFlow:\n",
    "  \n",
    "  * TensorFlow 1.2.1 or earlier requires cuDNN 5.1. ('cudnn64_5.dll')\n",
    "  * TensorFlow 1.3 or later requires cuDNN 6. ('cudnn64_6.dll')\n",
    "    \n",
    "  You may install the necessary DLL by downloading cuDNN from this URL:\n",
    "  https://developer.nvidia.com/cudnn\"\"\")\n",
    "    \n",
    "  if not candidate_explanation:\n",
    "    print(\"\"\"\n",
    "- All required DLLs appear to be present. Please open an issue on the\n",
    "  TensorFlow GitHub page: https://github.com/tensorflow/tensorflow/issues\"\"\")\n",
    "\n",
    "  sys.exit(-1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "ccbc1747ffb0f2942cc99bc27e4afc3262ba9f94"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "if BASE_MODEL=='VGG16':\n",
    "    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='RESNET52':\n",
    "    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='Xception':\n",
    "    from keras.applications.xception import Xception as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet169': \n",
    "    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n",
    "else:\n",
    "    raise ValueError('Unknown model: {}'.format(BASE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 45, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  brightness_range = [0.5, 1.5],\n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last',\n",
    "              preprocessing_function = preprocess_input)\n",
    "valid_args = dict(fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last',\n",
    "                  preprocessing_function = preprocess_input)\n",
    "\n",
    "core_idg = ImageDataGenerator(**dg_args)\n",
    "valid_idg = ImageDataGenerator(**valid_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c5cc31e3117fdfa923b2acb1e6542a7007f4f955"
   },
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "67136e1743dbbc4e07dba0d69f79231603f31d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 70 images\n",
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 30 images\n",
      "((30, 299, 299, 3), (30, 1))\n"
     ]
    }
   ],
   "source": [
    "train_gen = flow_from_dataframe(core_idg, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'has_ship_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE)\n",
    "\n",
    "# used a fixed dataset for evaluating the algorithm\n",
    "valid_x, valid_y = next(flow_from_dataframe(valid_idg, \n",
    "                               valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'has_ship_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = VALID_IMG_COUNT)) # one big batch\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "6122ccb9e58bfac6fa5e11c86121e78d9e5151b1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-66b642100189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmontage_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_x\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mRGB_FLIP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_gen' is not defined"
     ]
    }
   ],
   "source": [
    "t_x, t_y = next(train_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "ax1.imshow(montage_rgb((t_x-t_x.min())/(t_x.max()-t_x.min()))[:, :, ::RGB_FLIP], cmap='gray')\n",
    "ax1.set_title('images')\n",
    "ax2.plot(t_y)\n",
    "ax2.set_title('ships')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba08494eb9736ec3556b7c879143cdcdea89febf"
   },
   "source": [
    "# Build a Model\n",
    "We build the pre-trained top model and then use a global-max-pooling (we are trying to detect any ship in the image and thus max is better suited than averaging (which would tend to favor larger ships to smaller ones). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9fb62d14ec059f7f92d82e07b35822169c77112d"
   },
   "outputs": [],
   "source": [
    "base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n",
    "                              include_top = False, \n",
    "                                weights = 'imagenet')\n",
    "base_pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0bc7c0ee177697838d22aed4de046e7542027a10"
   },
   "source": [
    "## Setup the Subsequent Layers\n",
    "Here we setup the rest of the model which we will actually be training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2687377309d3cbbab1197f4eccd2b50ab996f5a6"
   },
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras.optimizers import Adam\n",
    "img_in = layers.Input(t_x.shape[1:], name='Image_RGB_In')\n",
    "img_noise = layers.GaussianNoise(GAUSSIAN_NOISE)(img_in)\n",
    "pt_features = base_pretrained_model(img_noise)\n",
    "pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "bn_features = layers.BatchNormalization()(pt_features)\n",
    "feature_dropout = layers.SpatialDropout2D(DROPOUT)(bn_features)\n",
    "gmp_dr = layers.GlobalMaxPooling2D()(feature_dropout)\n",
    "dr_steps = layers.Dropout(DROPOUT)(layers.Dense(DENSE_COUNT, activation = 'relu')(gmp_dr))\n",
    "out_layer = layers.Dense(1, activation = 'sigmoid')(dr_steps)\n",
    "\n",
    "ship_model = models.Model(inputs = [img_in], outputs = [out_layer], name = 'full_model')\n",
    "\n",
    "ship_model.compile(optimizer = Adam(lr=LEARN_RATE), \n",
    "                   loss = 'binary_crossentropy',\n",
    "                   metrics = ['binary_accuracy'])\n",
    "\n",
    "ship_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7282d18de3aff1cee12ff89b7d511a391702814f"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('boat_detector')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b67d808c0b8c7e28bff41e6d3858ff6f09dd626",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_gen.batch_size = BATCH_SIZE\n",
    "ship_model.fit_generator(train_gen, \n",
    "                         steps_per_epoch=train_gen.n//BATCH_SIZE,\n",
    "                      validation_data=(valid_x, valid_y), \n",
    "                      epochs=30, \n",
    "                      callbacks=callbacks_list,\n",
    "                      workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a168c8b1af446b800f6129104906003ededd61c4"
   },
   "outputs": [],
   "source": [
    "ship_model.load_weights(weight_path)\n",
    "ship_model.save('full_ship_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17edb177402ae51651692511827a7e9d60646533"
   },
   "source": [
    "# Run the test data\n",
    "We use the sample_submission file as the basis for loading and running the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4911811f267f9f3397a58902da9e75c6f261ad40"
   },
   "outputs": [],
   "source": [
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), 'test images found')\n",
    "submission_df = pd.read_csv('../input/sample_submission_v2.csv')\n",
    "submission_df['path'] = submission_df['ImageId'].map(lambda x: os.path.join(test_image_dir, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b3eea954bd883d598c6ac80167dfd4353b0f558"
   },
   "source": [
    "# Setup Test Data Generator\n",
    "We use the same generator as before to read and preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f75595679ba8606fd1ac15645b8612e117db0b30"
   },
   "outputs": [],
   "source": [
    "test_gen = flow_from_dataframe(valid_idg, \n",
    "                               submission_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'ImageId', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE, \n",
    "                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73ef7b3b2a74bf64968c79b4005075d4f0e23143"
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(3, 2, figsize = (20, 30))\n",
    "for (ax1, ax2), (t_x, c_img_names) in zip(m_axs, test_gen):\n",
    "    t_y = ship_model.predict(t_x)\n",
    "    t_stack = ((t_x-t_x.min())/(t_x.max()-t_x.min()))[:, :, :, ::RGB_FLIP]\n",
    "    ax1.imshow(montage_rgb(t_stack))\n",
    "    ax1.set_title('images')\n",
    "    alpha_stack = np.tile(np.expand_dims(np.expand_dims(t_y, -1), -1), [1, t_stack.shape[1], t_stack.shape[2], 1])\n",
    "    rgba_stack = np.concatenate([t_stack, alpha_stack], -1)\n",
    "    ax2.imshow(montage_rgb(rgba_stack))\n",
    "    ax2.set_title('ships')\n",
    "fig.savefig('test_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22f5f7e53cb82ff54bfb0e4ee818315d05c1e1af"
   },
   "source": [
    "# Prepare Submission\n",
    "Process all images (batchwise) and keep the score at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b103e0ce6ccae69dbf82a55067dc693efaeadf8f"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = BATCH_SIZE*2 # we can use larger batches for inference\n",
    "test_gen = flow_from_dataframe(valid_idg, \n",
    "                               submission_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'ImageId', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE, \n",
    "                              shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a38d343b2654f87934a88524ebc14a5759e07cb"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "all_scores = dict()\n",
    "for _, (t_x, t_names) in zip(tqdm_notebook(range(test_gen.n//BATCH_SIZE+1)),\n",
    "                            test_gen):\n",
    "    t_y = ship_model.predict(t_x)[:, 0]\n",
    "    for c_id, c_score in zip(t_names, t_y):\n",
    "        all_scores[c_id] = c_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4a942dbb4a939d73526dbb35745402b35785fdf4"
   },
   "source": [
    "# Show the Scores\n",
    "Here we see the scores and we have to decide about a cut-off for counting an image as ship or not. We can be lazy and pick 0.5 but some more rigorous cross-validation would definitely improve this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41ab9326407f59c983f3991ff736da8dd822605c"
   },
   "outputs": [],
   "source": [
    "submission_df['score'] = submission_df['ImageId'].map(lambda x: all_scores.get(x, 0))\n",
    "submission_df['score'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fae5322806f03112d8110755ca48a3bdb05eeded"
   },
   "source": [
    "# Make the RLE data if there is a ship\n",
    "Here we make the RLE data for a positive image (assume every pixel is ship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80acd5482d2a6117648a842b2f0da380bced79a5"
   },
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "# empty image\n",
    "zp_dim = 10\n",
    "out_img = np.ones((768-2*zp_dim, 768-2*zp_dim), dtype=bool)\n",
    "out_img = np.pad(out_img, ((zp_dim, zp_dim),), mode='constant', constant_values=0)\n",
    "plt.matshow(out_img)\n",
    "print(out_img.shape)\n",
    "pos_ship_str = rle_encode(out_img)\n",
    "print(pos_ship_str[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "580506b6e934b9a9a362deaf6b88e5d71c770405"
   },
   "outputs": [],
   "source": [
    "# add the whole image if it is above the threshold\n",
    "submission_df['EncodedPixels'] = submission_df['score'].map(lambda x: pos_ship_str if x>0.5 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b534a825f5a1997a935aa3e3f338da657024bc19"
   },
   "outputs": [],
   "source": [
    "out_df = submission_df[['ImageId', 'EncodedPixels']]\n",
    "out_df.to_csv('submission.csv', index=False)\n",
    "out_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07dd065b26b4018ea76bd7d90ee9639a2b2c7480"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
